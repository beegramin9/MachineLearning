{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Model Selection Module\n",
    "- train data, test data 분리하지 않고 머신러닝 수행"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "# x,y 데이터\n",
    "dt_clf.fit(iris.data , iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "pred = dt_clf.predict(iris.data)\n",
    "# y실제값, y햇\n",
    "accuracy_score(iris.target, pred)"
   ]
  },
  {
   "source": [
    "- 학습 데이터와 테스트 데이터(30%) 분리"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test 순서 중요\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris.data, iris.target, test_size = 0.3, random_state = 121 \n",
    "    # random_state: 랜덤으로 셔플할 때 사용되는 시드값\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier()\n",
    "# x,y 데이터\n",
    "dt_clf.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9555555555555556"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "pred = dt_clf.predict(X_test)\n",
    "# y실제값, y햇\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "source": [
    "# 교차 검증\n",
    "- 학습 데이터 셋, 테스트 데이터 셋 이렇게 둘로만 나누지 않고 검증 데이터 셋도 추가"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "붓꽃 데이터 세트 크기: 150\n\n#1 교차 검증 정확도 :1.0, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n#1 검증 세트 인덱스:[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29]\n\n#2 교차 검증 정확도 :0.9667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n#2 검증 세트 인덱스:[30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n 54 55 56 57 58 59]\n\n#3 교차 검증 정확도 :0.8667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n#3 검증 세트 인덱스:[60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n 84 85 86 87 88 89]\n\n#4 교차 검증 정확도 :0.9333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n#4 검증 세트 인덱스:[ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n 108 109 110 111 112 113 114 115 116 117 118 119]\n\n#5 교차 검증 정확도 :0.7333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n#5 검증 세트 인덱스:[120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n 138 139 140 141 142 143 144 145 146 147 148 149]\n\n## 평균 검증 정확도: 0.9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "kfold = KFold(n_splits=5)\n",
    "cv_accuracy = [] # 교차검증(Cross Validation) accuracy\n",
    "features, label = iris.data, iris.target\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "print('붓꽃 데이터 세트 크기:', features.shape[0])\n",
    "\n",
    "for train_index, test_index in kfold.split(features):\n",
    " # kfold.split( )으로 반환된 인덱스를 이용하여 학습용, 검증용 테스트 데이터 추출\n",
    " X_train, X_test = features[train_index], features[test_index]\n",
    " y_train, y_test = label[train_index], label[test_index]\n",
    " #학습 및 예측\n",
    " dt_clf.fit(X_train , y_train)\n",
    " pred = dt_clf.predict(X_test)\n",
    " n_iter += 1\n",
    " # 반복 시 마다 정확도 측정\n",
    " accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
    " train_size = X_train.shape[0]\n",
    " test_size = X_test.shape[0]\n",
    " print('\\n#{0} 교차 검증 정확도 :{1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'\n",
    " .format(n_iter, accuracy, train_size, test_size))\n",
    " print('#{0} 검증 세트 인덱스:{1}'.format(n_iter, test_index))\n",
    " cv_accuracy.append(accuracy)\n",
    "\n",
    "print('\\n## 평균 검증 정확도:', np.mean(cv_accuracy))"
   ]
  },
  {
   "source": [
    "- setosa, versicolor, virginica 데이터가 50개씩 들어가 있는데 k-fold를 앞에서 30개 인덱스씩 뽑아옴<br>\n",
    "세토사는 확연히 차이가 나기 때문에 1번세트처럼 세토사만 하면 1이 나옴<br>\n",
    "버지칼라랑 버지니카는 데이터가 구분이 잘 안 되었기 때문에 둘이 섞이면 잘 안나옴\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "즉, y값이 불균형한 분포일 때는 kFold가 잘 안먹힌다.\n",
    "이걸 해결하기 위해 나온 Stratified K-Fold"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2    50\n",
       "1    50\n",
       "0    50\n",
       "Name: label, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "import pandas as pd\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "iris_df['label'] = iris.target\n",
    "iris_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "## 교차 검증: 1\n학습 레이블 데이터 분포:\n 2    50\n1    50\nName: label, dtype: int64\n검증 레이블 데이터 분포:\n 0    50\nName: label, dtype: int64\n## 교차 검증: 2\n학습 레이블 데이터 분포:\n 2    50\n0    50\nName: label, dtype: int64\n검증 레이블 데이터 분포:\n 1    50\nName: label, dtype: int64\n## 교차 검증: 3\n학습 레이블 데이터 분포:\n 1    50\n0    50\nName: label, dtype: int64\n검증 레이블 데이터 분포:\n 2    50\nName: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 3개로 나눔. 일반 KFold\n",
    "kfold = KFold(n_splits=3)\n",
    "n_iter = 0\n",
    "for train_index, test_index in kfold.split(iris_df):\n",
    " n_iter += 1\n",
    " label_train= iris_df['label'].iloc[train_index]\n",
    " label_test= iris_df['label'].iloc[test_index]\n",
    " print('## 교차 검증: {0}'.format(n_iter))\n",
    " print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
    " print('검증 레이블 데이터 분포:\\n', label_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "## 교차 검증: 1\n학습 레이블 데이터 분포:\n 2    34\n1    33\n0    33\nName: label, dtype: int64\n검증 레이블 데이터 분포:\n 1    17\n0    17\n2    16\nName: label, dtype: int64\n## 교차 검증: 2\n학습 레이블 데이터 분포:\n 1    34\n2    33\n0    33\nName: label, dtype: int64\n검증 레이블 데이터 분포:\n 2    17\n0    17\n1    16\nName: label, dtype: int64\n## 교차 검증: 3\n학습 레이블 데이터 분포:\n 0    34\n2    33\n1    33\nName: label, dtype: int64\n검증 레이블 데이터 분포:\n 2    17\n1    17\n0    16\nName: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 3개로 나눔. Stratified K Fold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=3) # 요기만 다름\n",
    "n_iter = 0\n",
    "for train_index, test_index in skf.split(iris_df, iris_df['label']):\n",
    " n_iter += 1\n",
    " label_train= iris_df['label'].iloc[train_index]\n",
    " label_test= iris_df['label'].iloc[test_index]\n",
    " print('## 교차 검증: {0}'.format(n_iter))\n",
    " print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
    " print('검증 레이블 데이터 분포:\\n', label_test.value_counts())"
   ]
  },
  {
   "source": [
    "Stratified KFold 교차 검증"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "skfold = StratifiedKFold(n_splits=3)\n",
    "cv_accuracy = []\n",
    "features, label = iris.data, iris.target\n",
    "n_iter = 0\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n#1 교차 검증 정확도 :0.98, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n#1 검증 세트 인덱스:[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  50\n  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 100 101\n 102 103 104 105 106 107 108 109 110 111 112 113 114 115]\n\n#2 교차 검증 정확도 :0.94, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n#2 검증 세트 인덱스:[ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  67\n  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82 116 117 118\n 119 120 121 122 123 124 125 126 127 128 129 130 131 132]\n\n#3 교차 검증 정확도 :0.98, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n#3 검증 세트 인덱스:[ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  83  84\n  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 133 134 135\n 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in skfold.split(features, label):\n",
    " # kfold.split( )으로 반환된 인덱스를 이용하여 학습용, 검증용 테스트 데이터 추출\n",
    " X_train, X_test = features[train_index], features[test_index]\n",
    " y_train, y_test = label[train_index], label[test_index]\n",
    " #학습 및 예측\n",
    " dt_clf.fit(X_train , y_train)\n",
    " pred = dt_clf.predict(X_test)\n",
    " n_iter += 1\n",
    " # 반복 시 마다 정확도 측정\n",
    " accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
    " train_size = X_train.shape[0]\n",
    " test_size = X_test.shape[0]\n",
    " print('\\n#{0} 교차 검증 정확도 :{1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'\n",
    " .format(n_iter, accuracy, train_size, test_size))\n",
    " print('#{0} 검증 세트 인덱스:{1}'.format(n_iter, test_index))\n",
    " cv_accuracy.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "## 교차 검증: [0.98 0.94 0.98]\n평균 검증 정확도: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "print('## 교차 검증:', np.round(cv_accuracy,4))\n",
    "print('평균 검증 정확도:', np.mean(cv_accuracy))"
   ]
  },
  {
   "source": [
    "- 편리한 교차 검증 세트"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "## 교차 검증: [0.98 0.94 0.98]\n평균 검증 정확도: 0.9667\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(dt_clf, iris.data, iris.target, scoring='accuracy', cv=3) \n",
    "# dt_clf, x값, y값, scoring(=평가) = 'acuracy', 평가를 accuracy로 하겠다. cv = 3)\n",
    "print('## 교차 검증:', np.round(scores,4))\n",
    "print('평균 검증 정확도:', np.round(np.mean(scores),4))\n"
   ]
  },
  {
   "source": [
    "### GridSearchCV - 교차 검증, 최적 하이퍼 파라미터 튜닝을 한 번에"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'max_depth': [2,3,4],\n",
    "    'min_samples_split': [2,3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris.data, iris.target, test_size = 0.3, random_state = 121 \n",
    ")\n",
    "\n",
    "dtree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_dtree = GridSearchCV(dtree, param_grid = parameters, cv= 3,scoring = 'accuracy', refit = True) \n",
    "# 모델명, 하이퍼 파라미터, cv, scoring, refit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'max_depth': [2, 3, 4], 'min_samples_split': [2, 3]},\n",
       "             scoring='accuracy')"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "grid_dtree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00101876, 0.00083598, 0.00117413, 0.00099778, 0.00066582,\n",
       "        0.00105476]),\n",
       " 'std_fit_time': array([1.80485646e-05, 2.28830035e-04, 2.05849956e-04, 8.21085226e-04,\n",
       "        4.70839947e-04, 8.01167810e-04]),\n",
       " 'mean_score_time': array([0.0004189 , 0.        , 0.00053414, 0.00068331, 0.0003256 ,\n",
       "        0.00084607]),\n",
       " 'std_score_time': array([0.00059242, 0.        , 0.00041138, 0.00048318, 0.00046047,\n",
       "        0.00062214]),\n",
       " 'param_max_depth': masked_array(data=[2, 2, 3, 3, 4, 4],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_split': masked_array(data=[2, 3, 2, 3, 2, 3],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'max_depth': 2, 'min_samples_split': 2},\n",
       "  {'max_depth': 2, 'min_samples_split': 3},\n",
       "  {'max_depth': 3, 'min_samples_split': 2},\n",
       "  {'max_depth': 3, 'min_samples_split': 3},\n",
       "  {'max_depth': 4, 'min_samples_split': 2},\n",
       "  {'max_depth': 4, 'min_samples_split': 3}],\n",
       " 'split0_test_score': array([0.94285714, 0.94285714, 0.97142857, 0.97142857, 0.97142857,\n",
       "        0.94285714]),\n",
       " 'split1_test_score': array([0.91428571, 0.91428571, 0.91428571, 0.91428571, 0.91428571,\n",
       "        0.91428571]),\n",
       " 'split2_test_score': array([0.94285714, 0.94285714, 0.94285714, 0.94285714, 0.94285714,\n",
       "        0.94285714]),\n",
       " 'mean_test_score': array([0.93333333, 0.93333333, 0.94285714, 0.94285714, 0.94285714,\n",
       "        0.93333333]),\n",
       " 'std_test_score': array([0.0134687 , 0.0134687 , 0.02332847, 0.02332847, 0.02332847,\n",
       "        0.0134687 ]),\n",
       " 'rank_test_score': array([4, 4, 1, 1, 1, 4])}"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "grid_dtree.cv_results_\n",
    "# 잘 안보이니까 데이터프레임으로 만들어보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                     params  mean_test_score  rank_test_score  \\\n",
       "0  {'max_depth': 2, 'min_samples_split': 2}         0.933333                4   \n",
       "1  {'max_depth': 2, 'min_samples_split': 3}         0.933333                4   \n",
       "2  {'max_depth': 3, 'min_samples_split': 2}         0.942857                1   \n",
       "3  {'max_depth': 3, 'min_samples_split': 3}         0.942857                1   \n",
       "4  {'max_depth': 4, 'min_samples_split': 2}         0.942857                1   \n",
       "5  {'max_depth': 4, 'min_samples_split': 3}         0.933333                4   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  \n",
       "0           0.942857           0.914286           0.942857  \n",
       "1           0.942857           0.914286           0.942857  \n",
       "2           0.971429           0.914286           0.942857  \n",
       "3           0.971429           0.914286           0.942857  \n",
       "4           0.971429           0.914286           0.942857  \n",
       "5           0.942857           0.914286           0.942857  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>params</th>\n      <th>mean_test_score</th>\n      <th>rank_test_score</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n      <td>0.933333</td>\n      <td>4</td>\n      <td>0.942857</td>\n      <td>0.914286</td>\n      <td>0.942857</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n      <td>0.933333</td>\n      <td>4</td>\n      <td>0.942857</td>\n      <td>0.914286</td>\n      <td>0.942857</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n      <td>0.942857</td>\n      <td>1</td>\n      <td>0.971429</td>\n      <td>0.914286</td>\n      <td>0.942857</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n      <td>0.942857</td>\n      <td>1</td>\n      <td>0.971429</td>\n      <td>0.914286</td>\n      <td>0.942857</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>{'max_depth': 4, 'min_samples_split': 2}</td>\n      <td>0.942857</td>\n      <td>1</td>\n      <td>0.971429</td>\n      <td>0.914286</td>\n      <td>0.942857</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>{'max_depth': 4, 'min_samples_split': 3}</td>\n      <td>0.933333</td>\n      <td>4</td>\n      <td>0.942857</td>\n      <td>0.914286</td>\n      <td>0.942857</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "score_df = pd.DataFrame(grid_dtree.cv_results_)\n",
    "score_df[['params','mean_test_score','rank_test_score','split0_test_score','split1_test_score','split2_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'max_depth': 3, 'min_samples_split': 2}"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "grid_dtree.best_params_\n",
    "# 하이퍼 파라미터를 이렇게 줬을 때 결과가 제일 좋더라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9428571428571427"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "grid_dtree.best_score_\n",
    "# 그때의 score는?"
   ]
  }
 ]
}