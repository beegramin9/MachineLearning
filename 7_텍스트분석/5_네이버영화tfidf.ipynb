{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('prophet': conda)",
   "metadata": {
    "interpreter": {
     "hash": "5e48e52ea031c0749f6c7450d6e984e2a9b420046de7854ab875b07076570244"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 네이버 영화 감성 분석 -TfidfVectorizer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/movie_train.tsv',sep='\\t')\n",
    "test_df = pd.read_csv('./data/movie_test.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()\n",
    "def tw_tokenizer(text):\n",
    "    tokens_ko = okt.morphs(text)\n",
    "    return tokens_ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "tvector = TfidfVectorizer(tokenizer = tw_tokenizer, ngram_range = (1,2),\n",
    "min_df = 3, max_df = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_df=0.9, min_df=3, ngram_range=(1, 2),\n",
       "                tokenizer=<function tw_tokenizer at 0x000002161FA47DC0>)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "%time\n",
    "tvector.fit(train_df.document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "X_train_tvect = tvector.transform(train_df['document'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "X_test_tvect = tvector.transform(test_df['document'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df.label.values\n",
    "y_test = test_df.label.values"
   ]
  },
  {
   "source": [
    "## LogisticRegression으로 학습/예측/평가"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8590060210225533"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(C=3.5)\n",
    "lr_clf.fit(X_train_tvect, y_train)\n",
    "pred = lr_clf.predict(X_test_tvect)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "review1 = \"진짜 개노잼이다... 1편이랑 같은 감독맞나?러닝타임도 길어서 개지루함 ㄹㅇ\"\n",
    "review2 = \"이런 사랑영화가 다시 나올 수 있을까?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "review1 = re.sub('[^ㄱ-ㅎㅏ-ㅣ가-힣 ]', '', review1)\n",
    "review_tvect = tvector.transform([review1])\n",
    "pred = lr_clf.predict(review_tvect)\n",
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "review2 = re.sub('[^ㄱ-ㅎㅏ-ㅣ가-힣 ]', '', review2)\n",
    "review_tvect = tvector.transform([review2])\n",
    "pred = lr_clf.predict(review_tvect)\n",
    "pred[0]"
   ]
  },
  {
   "source": [
    "## GridSearchCV로 최적 파라미터 찾기"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:  1.3min finished\n",
      "{'C': 3.5} 0.8552174002510443\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'C': [1,3,3.5,5,10]\n",
    "}\n",
    "grid_cv = GridSearchCV(lr_clf, param_grid=params, cv=3, verbose=1, scoring='accuracy')\n",
    "grid_cv.fit(X_train_tvect, y_train)\n",
    "print(grid_cv.best_params_, grid_cv.best_score_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = grid_cv.predict(X_train_tvect)\n",
    "acc = accuracy_score(y_test, pred)\n",
    "print(f'cvector + lr_clf 정확도: {acc:.4f}')"
   ]
  }
 ]
}